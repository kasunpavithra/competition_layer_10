{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27b63865",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "class MyModel(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, C=83.4, kernel='rbf', gamma='scale', n_components=None, variance_t=0.001, corr_t= 0.9,resample=False, random_state=None):\n",
    "        \"\"\"\n",
    "        Initialize the MyModel with hyperparameters.\n",
    "\n",
    "        Parameters:\n",
    "        - C: Regularization parameter\n",
    "        - kernel: Kernel function for the SVM ('linear', 'rbf', 'poly', etc.)\n",
    "        - gamma: Kernel coefficient for 'rbf', 'poly', and 'sigmoid'\n",
    "        - random_state: Seed for random number generation\n",
    "        \"\"\"\n",
    "        self.C = C\n",
    "        self.kernel = kernel\n",
    "        self.gamma = gamma\n",
    "        self.random_state = random_state\n",
    "        self.n_components = n_components\n",
    "        self.variance_t = variance_t\n",
    "        self.corr_t = corr_t\n",
    "        self.model = None\n",
    "        self.drop = None\n",
    "        self.sscaler = None,\n",
    "        self.pcac = None\n",
    "        self.resample = resample\n",
    "\n",
    "    def fit(self, x_train, y_train):\n",
    "        \"\"\"\n",
    "        Fit the SVM model to the training data.\n",
    "\n",
    "        Parameters:\n",
    "        - X: Training data features\n",
    "        - y: Target labels\n",
    "        \"\"\"\n",
    "        \n",
    "        if(self.resample):\n",
    "            # Instantiate SMOTE with desired sampling strategy\n",
    "            smote = SMOTE(sampling_strategy='auto', random_state=42)  # You can adjust the sampling strategy\n",
    "\n",
    "            # Fit and transform the dataset\n",
    "            x_resampled, y_resampled = smote.fit_resample(x_train, y_train)\n",
    "        else:\n",
    "            x_resampled, y_resampled = x_train, y_train\n",
    "            \n",
    "        #using variance threshold\n",
    "        self.drop = self.variance_treshould_invf(x_resampled)\n",
    "        \n",
    "        vx_train = x_resampled.drop(columns=self.drop,axis=1)\n",
    "        \n",
    "        # using correlation\n",
    "#         next_drop = self.correlation(vx_train)\n",
    "        next_drop = set()\n",
    "        self.drop = self.drop + list(next_drop)\n",
    "        \n",
    "        cvx_train = vx_train.drop(columns=next_drop,axis=1)\n",
    "        \n",
    "        self.sscaler = StandardScaler()\n",
    "\n",
    "        # fit the scaler\n",
    "        scvx_train = pd.DataFrame(self.sscaler.fit_transform(cvx_train), columns=cvx_train.columns)\n",
    "        \n",
    "        # define the pca\n",
    "        if(self.n_components):\n",
    "            self.pcac = PCA(n_components= self.n_components)\n",
    "\n",
    "            pscvx_train = self.pcac.fit_transform(scvx_train)\n",
    "            print(f\"No of new Lables: {len(pscvx_train[0])}\")\n",
    "        else:\n",
    "            pscvx_train = scvx_train\n",
    "        \n",
    "        \n",
    "        self.model = SVC(C=self.C, kernel=self.kernel, gamma=self.gamma, random_state=self.random_state, class_weight=\"balanced\")\n",
    "        self.model.fit(pscvx_train, y_resampled)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Make predictions using the trained SVM model.\n",
    "\n",
    "        Parameters:\n",
    "        - X: Input data for predictions\n",
    "\n",
    "        Returns:\n",
    "        - Predicted labels\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.model is None:\n",
    "            raise ValueError(\"Model has not been trained. Please call fit() first.\")\n",
    "            \n",
    "        cvx_valid = X.drop(columns=self.drop,axis=1)\n",
    "        \n",
    "        scvx_valid = pd.DataFrame(self.sscaler.transform(cvx_valid), columns=cvx_valid.columns)\n",
    "        \n",
    "        if self.n_components:\n",
    "            pscvx_valid = self.pcac.transform(scvx_valid)\n",
    "        else:\n",
    "            pscvx_valid = scvx_valid\n",
    "        return self.model.predict(pscvx_valid)\n",
    "    \n",
    "    def variance_treshould_invf(self, X):\n",
    "        should_drop = []\n",
    "        stds = X.describe().loc[\"std\"]\n",
    "        max_variance = max(stds)**2\n",
    "        for i in range(0, len(stds)):\n",
    "            if (stds[i]**2)< (self.variance_t):\n",
    "                should_drop.append(f\"feature_{i+1}\")\n",
    "        return should_drop\n",
    "    \n",
    "    def correlation(self, X):\n",
    "      col_corr = set()\n",
    "      corr_matrix = X.corr()\n",
    "      for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i):\n",
    "          if abs(corr_matrix.iloc[i,j])>= self.corr_t:\n",
    "            colname = corr_matrix.columns[i]\n",
    "            col_corr.add(colname)\n",
    "      return col_corr\n",
    "\n",
    "    def getValidationSet(self):\n",
    "        return self.x_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f22e4c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_to_file(text):\n",
    "    with open(\"outputs1_10.txt\", \"a\") as file:\n",
    "        # Write content to the file\n",
    "        file.write(f\"{text}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8119b40f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for label_1: 0.968\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "all_labels = [\"label_1\",\"label_2\",\"label_3\", \"label_4\"]\n",
    "for label in all_labels:\n",
    "    droping_labels = all_labels.copy()\n",
    "    droping_labels.remove(label)\n",
    "    \n",
    "    train = pd.read_csv(\"./train.csv\")\n",
    "    valid = pd.read_csv(\"./valid.csv\")\n",
    "\n",
    "    train.drop(droping_labels, axis=1, inplace=True)\n",
    "    valid.drop(droping_labels, axis=1, inplace=True)\n",
    "    \n",
    "    if(len(train.columns[train.isnull().any()])>0):\n",
    "        print(f\"{label} has missing values in train set\")\n",
    "        train.dropna(inplace=True)\n",
    "        \n",
    "    if(len(valid.columns[train.isnull().any()])>0):\n",
    "        print(f\"{label} has missing values in valid set\")\n",
    "        valid.dropna(inplace=True)\n",
    "    \n",
    "    # splitting features and the label\n",
    "    x_train = train.drop([label], axis=1)\n",
    "    y_train = train[label]\n",
    "    x_valid = valid.drop([label], axis=1)\n",
    "    y_valid = valid[label]\n",
    "    \n",
    "    \n",
    "    # Create an instance of MyModel\n",
    "    my_model = MyModel()\n",
    "\n",
    "    # Fit the model to the training data\n",
    "    my_model.fit(x_train, y_train)\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    y_pred = my_model.predict(x_valid)\n",
    "\n",
    "    # Print the accuracy of the model\n",
    "    accuracy = (y_pred == y_valid).mean()\n",
    "    print(f\"Accuracy for {label}: {accuracy}\")\n",
    "    append_to_file(f\"Initial accuracy for {label}: {accuracy}\")\n",
    "\n",
    "    # Example of using RandomizedSearchCV to tune hyperparameters\n",
    "    param_dist = {\n",
    "        'C': uniform(0.1, 100.0),\n",
    "        'kernel': ['linear', 'rbf', 'poly'],\n",
    "        'gamma': ['scale', 'auto']+[int(x)/1000 for x in np.linspace(100, 10000, 20)],\n",
    "        'n_components': [None, 0.97, 0.98, 0.99, 0.999],\n",
    "        'variance_t': [0.001],\n",
    "        'corr_t': [None],\n",
    "        'resample': [True, False]\n",
    "    }\n",
    "\n",
    "    random_search = RandomizedSearchCV(\n",
    "        estimator=my_model,\n",
    "        param_distributions=param_dist,\n",
    "        n_iter=20,  # Number of random combinations to try\n",
    "        cv=5,  # Number of cross-validation folds\n",
    "        verbose=2,\n",
    "        random_state=42,  # Set a random seed for reproducibility\n",
    "        n_jobs=-1  # Use all available CPU cores for parallel computation\n",
    "    )\n",
    "    random_search.fit(x_train, y_train)\n",
    "\n",
    "    print(\"Best hyperparameters found by RandomizedSearchCV:\")\n",
    "    print(random_search.best_params_)\n",
    "    append_to_file(f\"Best params for {label} : {random_search.best_params_}\")\n",
    "    \n",
    "    print(\"Best Score:\", random_search.best_score_)\n",
    "    append_to_file(f\"Best score for {label} : {random_search.best_score_}\")\n",
    "    \n",
    "    # Perform cross-validation to evaluate the model with the best hyperparameters\n",
    "#     cross_val_scores = cross_val_score(random_search, X, y, cv=5, n_jobs=-1)\n",
    "\n",
    "    # Print cross-validation scores\n",
    "#     print(\"Cross-Validation Scores:\", cross_val_scores)\n",
    "#     append_to_file(f\"Cross-Validation Scores for {label} : {cross_val_scores} \\n\")\n",
    "#     print(\"Mean CV Score:\", np.mean(cross_val_scores))\n",
    "#     append_to_file(f\"Mean CV Score for {label} : {np.mean(cross_val_scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "282306bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['label_2'], dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "007e465f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['label_2'], dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fccca4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
